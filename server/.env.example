# =============================================================================
# AI Help Desk - Backend Environment Configuration
# =============================================================================
# Copy this file to .env and update with your actual values
# =============================================================================

# Application Settings
APP_NAME=AI Help Desk
APP_VERSION=1.0.0
ENVIRONMENT=development
DEBUG=false
LOG_LEVEL=INFO

# =============================================================================
# Database Configuration
# =============================================================================
# LOCAL DEVELOPMENT (SQLite - No setup required):
DATABASE_URL=sqlite+aiosqlite:///./helpdesk.db

# PRODUCTION (PostgreSQL with pgvector on Render/Neon):
# Get connection string from your database provider dashboard
# Format: postgresql+asyncpg://user:password@host:5432/dbname
# DATABASE_URL=postgresql+asyncpg://user:password@host.render.com/ai_helpdesk

# =============================================================================
# LLM Provider Configuration
# =============================================================================
# Get your FREE Gemini API key: https://aistudio.google.com/app/apikey
# Supported providers: gemini, openai, anthropic, mock

USE_LLM=true
LLM_PROVIDER=gemini
LLM_API_KEY=your-gemini-api-key-here
LLM_MODEL=gemini-2.0-flash-exp
LLM_TEMPERATURE=0.0

# Option 2: Use OpenAI (Requires paid API key)
# USE_LLM=true
# LLM_PROVIDER=openai
# LLM_API_KEY=sk-your-openai-api-key-here
# LLM_MODEL=gpt-4
# LLM_TEMPERATURE=0.0

# Option 3: KB-Only Mode (No LLM, instant responses)
# USE_LLM=false
# LLM_PROVIDER=mock

# =============================================================================
# Embedding Configuration
# =============================================================================
# Sentence Transformers - Runs locally, no API key needed
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
EMBEDDING_DIMENSION=384

# =============================================================================
# RAG (Retrieval-Augmented Generation) Configuration
# =============================================================================
RAG_TOP_K=5
RAG_SIMILARITY_THRESHOLD=0.5

# =============================================================================
# CORS Configuration
# =============================================================================
# LOCAL DEVELOPMENT:
CORS_ORIGINS=["http://localhost:5173","http://localhost:3000"]

# PRODUCTION (Update with your actual Vercel frontend URL):
# CORS_ORIGINS=["https://your-frontend.vercel.app","http://localhost:5173"]
